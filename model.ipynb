{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from glob import glob\n",
    "from sklearn.metrics import *\n",
    "from torch import FloatTensor\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BraTS(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, path: str) -> None:\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.dirs = os.listdir(path)\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dirs)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[FloatTensor, FloatTensor]:\n",
    "        # determine the MRI paths\n",
    "        mri_path = os.path.join(self.path, self.dirs[idx])\n",
    "        t1_path  = glob(mri_path + '/*t1.*')[0]\n",
    "        t1c_path = glob(mri_path + '/*t1c*')[0]\n",
    "        t2_path  = glob(mri_path + '/*t2*')[0]\n",
    "        t2f_path = glob(mri_path + '/*fl*')[0]\n",
    "        seg_path = glob(mri_path + '/*seg*')[0]\n",
    "\n",
    "        # read the MRI\n",
    "        t1_img  = nib.load(t1_path ).get_fdata()\n",
    "        t1c_img = nib.load(t1c_path).get_fdata()\n",
    "        t2_img  = nib.load(t2_path ).get_fdata()\n",
    "        t2f_img = nib.load(t2f_path).get_fdata()\n",
    "        seg_img = nib.load(seg_path).get_fdata()\n",
    "\n",
    "        # compose a 4 channel image\n",
    "        mri_4x = np.stack((t1_img, t1c_img, t2_img, t2f_img))\n",
    "\n",
    "        # transform to tensors\n",
    "        mri_tensor = torch.tensor(mri_4x, dtype=torch.float32).swapaxes(1,3)\n",
    "        seg_tensor = torch.tensor(seg_img, dtype=torch.float32)\n",
    "\n",
    "        # rescale to interval [0, 1]\n",
    "        mri_tensor = self.normalize(mri_tensor)\n",
    "        return mri_tensor, seg_tensor\n",
    "\n",
    "\n",
    "    def normalize(self, data: FloatTensor) -> FloatTensor:\n",
    "        # normalize a tensor to interval [0, 1]\n",
    "        data_min, data_max = torch.min(data), torch.max(data)\n",
    "        return (data - data_min) / (data_max - data_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brats = BraTS('./data')\n",
    "brats[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnnLayer3d(in_filters, out_filters, kernel_size=3, leak_rate=0.01):\n",
    "    padding = kernel_size//2\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv3d(in_filters, out_filters, kernel_size, padding=padding), \n",
    "        torch.nn.BatchNorm3d(out_filters),\n",
    "        torch.nn.LeakyReLU(leak_rate)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetBlock3d(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, mid_channels, out_channels=None, layers=1, sub_network=None, filter_size=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # preparing the layers used to process the input\n",
    "        in_layers = [cnnLayer3d(in_channels, mid_channels, filter_size)]\n",
    "        \n",
    "        # double the number of inputs to the output if there's a subnetwork\n",
    "        inputs_to_outputs = 1 if sub_network is None else 2\n",
    "\n",
    "        # preparing the layers used to process the final output, which has extra input channels from any sub-network\n",
    "        out_layers = [cnnLayer3d(mid_channels*inputs_to_outputs, mid_channels, filter_size)]\n",
    "        \n",
    "        # make the additional hidden layers used for the input and output\n",
    "        for _ in range(layers-1):\n",
    "            in_layers.append(cnnLayer3d(mid_channels, mid_channels, filter_size))\n",
    "            out_layers.append(cnnLayer3d(mid_channels, mid_channels, filter_size))\n",
    "        \n",
    "        # use 1x1 Convolutions to ensure a specific output size\n",
    "        if out_channels is not None:\n",
    "            out_layers.append(torch.nn.Conv3d(mid_channels, out_channels, 1, padding=0))\n",
    "\n",
    "        # define the three sub-networks:\n",
    "\n",
    "        #1) in_model performs the intial rounds of convolution\n",
    "        self.in_model = torch.nn.Sequential(*in_layers)\n",
    "\n",
    "        #2) our subnetwork works on the max-pooled result. We will add the pooling and up-scaling directly into the sub-model\n",
    "        if sub_network is not None:\n",
    "            self.bottleneck = torch.nn.Sequential(\n",
    "                torch.nn.MaxPool3d(2),\n",
    "                sub_network,\n",
    "                torch.nn.ConvTranspose3d(mid_channels, mid_channels, filter_size, padding=filter_size//2, output_padding=1, stride=2)\n",
    "            )\n",
    "        else:\n",
    "            self.bottleneck = None\n",
    "        \n",
    "        #3) the output model that processes the concatenated result, or just the output from in_model if no sub-network was given\n",
    "        self.out_model = torch.nn.Sequential(*out_layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # compute the convolutions at full scale\n",
    "        full_scale_result = self.in_model(x) # shape (B, C, D, W, H)\n",
    "\n",
    "        # check if there's a bottleneck to apply\n",
    "        if self.bottleneck is not None:\n",
    "            # initial shape (B, C, D, W, H)\n",
    "            bottle_result = self.bottleneck(full_scale_result)\n",
    "            # final shape (B, 2*C, D, W, H)\n",
    "            full_scale_result = torch.cat([full_scale_result, bottle_result], dim=1)\n",
    "    \n",
    "        # compute the output on the concatenated result\n",
    "        return self.out_model(full_scale_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet3d_model = torch.nn.Sequential(\n",
    "    UNetBlock3d(4, 32, layers=2,\n",
    "    sub_network= UNetBlock3d(32, 64, out_channels=32, layers=2,\n",
    "        sub_network=UNetBlock3d(64, 128, out_channels=64, layers=2)\n",
    "        ),\n",
    "    ),\n",
    "    torch.nn.Conv3d(32, 4, (3,3), padding=1), # shape (B, 4, D, W, H)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(\n",
    "    model,              # model's instance\n",
    "    optimizer,          # optimizer instance\n",
    "    criterion,          # loss function\n",
    "    dataloaders,        # dictionary of train and (optional) valid dataloaders\n",
    "    epochs=10,          # number of epochs\n",
    "    # lr=3e-4,          # learning rate (default: Karpathyâ€™s constant)\n",
    "    device='auto',      # device for computations\n",
    "    score_funcs={},     # score functions to use from sklearn\n",
    "    checkpoint='',      # name of the file for the checkpoint\n",
    "    save_best=False\n",
    "    ):\n",
    "\n",
    "    # place the model on the selected device\n",
    "    if device == 'auto':\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # create a dictionary dataloader if a single dataloader is passed\n",
    "    if not isinstance(dataloaders, dict):\n",
    "        dataloaders = {'train': dataloaders}\n",
    "    \n",
    "    # set up a dictionary of items to track\n",
    "    track_list = ['epoch', 'time']\n",
    "    # check number of phases to track\n",
    "    if len(dataloaders) > 1:\n",
    "        phases = ['train', 'valid']\n",
    "    else:\n",
    "        phases = ['train']\n",
    "    # add loss tracking for each phase\n",
    "    track_list.extend([phase + '_loss' for phase in phases])\n",
    "    # add score functions tracking for each phase\n",
    "    if score_funcs:\n",
    "        key_list = [key for key in score_funcs.keys()]\n",
    "        track_list.extend(\n",
    "            [phase + '_' + key for key in key_list for phase in phases]\n",
    "            )\n",
    "    # instantiate the dictionary log to track\n",
    "    train_log = {x: [] for x in track_list}\n",
    "    # print(train_log)\n",
    "\n",
    "    # initialize time for logging\n",
    "    train_time = float()\n",
    "    best_loss = float()\n",
    "\n",
    "    # iterate through epochs\n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "\n",
    "        # set up\n",
    "        start_time = time.time()\n",
    "        train_epoch_loss, valid_epoch_loss = [], []\n",
    "\n",
    "        # iterate through phases:\n",
    "        for phase in phases:\n",
    "\n",
    "            # set up\n",
    "            y_true, y_pred = [], []\n",
    "\n",
    "            # set model to train or eval mode\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            if phase == 'valid':\n",
    "                model.eval()\n",
    "\n",
    "            # iterate over batches\n",
    "            for inputs, labels in tqdm(dataloaders[phase], leave=False):\n",
    "\n",
    "                # place the data on the selected device\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # enable autograd differentiation only for training\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "                    # forward propagation\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward propagation\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                    # logging the loss\n",
    "                    if phase == 'train':\n",
    "                        train_epoch_loss.append(loss.item())\n",
    "                    if phase == 'valid':\n",
    "                        valid_epoch_loss.append(loss.item())\n",
    "\n",
    "                # score functions calculation\n",
    "                if len(score_funcs) > 0 and isinstance(labels, torch.Tensor):\n",
    "                    # moving labels & outputs to CPU arrays\n",
    "                    labels = labels.detach().cpu().numpy()\n",
    "                    outputs = outputs.detach().cpu().numpy()\n",
    "                    # save the labels & outputs for later\n",
    "                    y_true.extend(labels.tolist())\n",
    "                    y_pred.extend(outputs.tolist())\n",
    "            \n",
    "            y_true, y_pred = np.asarray(y_true), np.asarray(y_pred)\n",
    "            if len(y_pred.shape) == 2 and y_pred.shape[1] > 1: #We have a classification problem, convert to labels\n",
    "                y_pred = np.argmax(y_pred, axis=1)\n",
    "            #Else, we assume we are working on a regression problem\n",
    "        \n",
    "            # calculate and logging the score functions\n",
    "            for key, score_func in score_funcs.items():\n",
    "                key = phase + '_' + key\n",
    "                try:\n",
    "                    train_log[key].append(score_func(y_true, y_pred))\n",
    "                except:\n",
    "                    train_log[key].append(float(\"NaN\"))\n",
    "\n",
    "        # stop timer and check time\n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        train_time += epoch_time\n",
    "\n",
    "        # logging the epochs, time, losses\n",
    "        for key in train_log.keys():\n",
    "            if key == 'epoch':\n",
    "                train_log[key].append(epoch)\n",
    "            elif key == 'time':\n",
    "                train_log[key].append(round(train_time, 2))\n",
    "            elif key == 'train_loss':\n",
    "                train_log[key].append(np.mean(train_epoch_loss))\n",
    "            elif key == 'valid_loss':\n",
    "                train_log['valid_loss'].append(\n",
    "                    np.mean(valid_epoch_loss) if not valid_epoch_loss else 'nan'\n",
    "                    )\n",
    "    \n",
    "        # save a checkpoint\n",
    "        if checkpoint:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state': model.state_dict(),\n",
    "                'optimizer_state': optimizer.state_dict(),\n",
    "                'log' : train_log\n",
    "                },\n",
    "                checkpoint\n",
    "            )\n",
    "        \n",
    "        # deep copy the model\n",
    "        if save_best and phase == 'valid' and train_log['valid_loss'][-1] < best_loss:\n",
    "            best_loss = train_log['valid_loss'][-1]\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # return a dataframe object with all the logging information\n",
    "    if save_best:\n",
    "        return (\n",
    "            pd.DataFrame.from_dict(train_log).set_index('epoch'),\n",
    "            model.load_state_dict(best_model)\n",
    "        )\n",
    "    else:\n",
    "        return pd.DataFrame.from_dict(train_log).set_index('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "optimizer = torch.optim.AdamW(unet3d_model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(brats, (100, len(brats)-100))\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "\n",
    "train_results = train_evaluate(\n",
    "    model=unet3d_model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    dataloaders=train_loader,\n",
    "    epochs=1,\n",
    "    score_funcs={'Ac':accuracy_score, 'F1': f1_score},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ca92273d36a7b90133d4e2c954bcb441f65b17fc1b63676b74e9dd7382de1de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
